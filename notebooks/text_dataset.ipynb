{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02861583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchtext\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "DATA_FOLDER_PTH=os.path.join(os.getcwd(), os.pardir, 'data')\n",
    " \n",
    "TRAIN_AUDIO_FOLDER_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/train', 'train_splits')\n",
    "TRAIN_TEXT_FILE_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/train', 'train_sent_emo.csv')\n",
    " \n",
    "DEV_AUDIO_FOLDER_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/dev', 'dev_splits_complete')\n",
    "DEV_TEXT_FILE_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/dev', 'dev_sent_emo.csv')\n",
    " \n",
    "TEST_AUDIO_FOLDER_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/test', 'output_repeated_splits_test')\n",
    "TEST_TEXT_FILE_PTH=os.path.join(DATA_FOLDER_PTH, 'raw/MELD/test', 'test_sent_emo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "78076cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \n",
    "    # dataset_type = train/validation/test\n",
    "    # label_target = Emotion/Sentiment\n",
    "    # embedding_dim = 50/100/200/300\n",
    "    \n",
    "    def __init__(self, dataset_type = 'train', label_target = 'Emotion', embedding_dim = 50):\n",
    "\n",
    "        self.dataset_type = dataset_type\n",
    "        self.label_target = label_target\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.glove = torchtext.vocab.GloVe(name=\"6B\", dim = self.embedding_dim) \n",
    "        \n",
    "        if self.dataset_type == 'train':\n",
    "            self.data = pd.read_csv(TRAIN_TEXT_FILE_PTH, encoding='utf-8')\n",
    "        if self.dataset_type == 'validation':\n",
    "            self.data = pd.read_csv(DEV_TEXT_FILE_PTH, encoding='utf-8')\n",
    "#         if self.dataset_type == 'test':\n",
    "#             self.data = pd.read_csv(TRAIN_TEXT_FILE_PTH, encoding='utf-8')\n",
    "\n",
    "        self.datasetSize = len(self.data)\n",
    "        self.maxSentLength = int(self.calcMaxSentLength())\n",
    "        self.padTensor = torch.zeros(size = (self.maxSentLength, self.embedding_dim))\n",
    "        \n",
    "        self.labels_idx = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5,'anger': 6}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = data['Utterance'][idx]\n",
    "        label = data[self.label_target][idx]\n",
    "        \n",
    "        sent_embeddings = self.get_embeddings(sentence)\n",
    "        sent_embeddings = pad_sequence([sent_embeddings, self.padTensor], batch_first=True)[0]\n",
    "        \n",
    "        label_id = torch.tensor(self.labels_idx[label], dtype = torch.long)\n",
    "        \n",
    "        #print(sent_embeddings, label_id)\n",
    "        \n",
    "        return sent_embeddings, label_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datasetSize\n",
    "    \n",
    "    def get_embeddings(self, sentence):\n",
    "        \n",
    "        sent_embeddings = None\n",
    "        for word in sentence.split():                   \n",
    "            word = word.translate(str.maketrans('', '', string.punctuation)).lower() # strip punctuations and lowercase\n",
    "            word_emb = self.glove[word]\n",
    "                \n",
    "            if sent_embeddings is None:\n",
    "                sent_embeddings = list([word_emb])\n",
    "            else:\n",
    "                sent_embeddings.append(word_emb)\n",
    "            \n",
    "        sent_embeddings = torch.stack(sent_embeddings)\n",
    "\n",
    "        return sent_embeddings\n",
    "    \n",
    "    def calcMaxSentLength(self):\n",
    "        corpus = data['Utterance']\n",
    "\n",
    "        sentence_length = pd.DataFrame(np.zeros(data['Utterance'].size), columns=['Length'])\n",
    "\n",
    "        for i, val in enumerate(corpus):\n",
    "\n",
    "            val = str(val)\n",
    "            tokens = val.split()\n",
    "\n",
    "            sentence_length.loc[i, 'Length'] = len(tokens)\n",
    "            \n",
    "        return max(sentence_length['Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3f587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
